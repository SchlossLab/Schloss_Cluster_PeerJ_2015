---
title: "**The difference between precision and accuracy in assigning 16S rRNA gene sequences to operational taxonomic units**"
author: Patrick D. Schloss
date: '`r format(Sys.Date(), format="%B %d, %Y")`'
bibliography: references.bib
output:
  html_document:
    includes:
      in_header: header.tex
csl: peerj.csl
fontsize: 11pt
geometry: margin=1.0in
---


## Introduction

The ability to affordably generate millions of 16S rRNA gene sequences has allowed microbial ecologists to thoroughly characterize the microbial community composition of hundreds of samples. To simplify the complexity of these large datasets, it is helpful to cluster sequences into meaningful bins. These bins, known as operational taxonomic units (OTUs), are commonly used to compare the biodiversity contained within and between different samples. Such comparisons have enabled researchers to characterize the microbiota associated with the human body (REF), soil (REF), aquatic ecosystems (REF), and numerous other environments. Within the field of microbial ecology a convention has emerged where sequences are clustered into OTUs using a threshold of 3% dissimilarity or 97% similarity. One advantage of the OTU-based approach is that the definition of the bins is operational and can be changed to suit the needs of the particular project. However, with the dissemination of clustering algorithms within packages such as mothur and QIIME and stand-alone tools (REFS), it is important to understand how different clustering methods implement this conventional OTU threshold. Furthermore, it is necessary to understand how algorithm choice affects the precision and accuracy of assigning sequences to OTUs. Broadly speaking, three approaches have been developed to assign sequences to OTUs.

The first approach has been referred to as phylotyping or closed reference clustering. This approach involves comparing sequences to a curated database and then clustering sequences together that are similar to the same reference sequence. Reference-based clustering methods suffer when the reference sequences do not reflect the composition of the community. If a large fraction of sequences are novel, then they cannot be assigned to an OTU. In addition, the reference sequences used in this application are selected because they are less than 97% similar to each other over the full length of the gene; however, it is known that the commonly used variable regions within the 16S rRNA gene do not evolve at the same rate as the full-length gene. Thus, a sequence representing a fragment of the gene may be more than 97% similar to multiple reference sequences. Because of this, defining OTUs in the closed-reference approach is complicated because two sequences might be 97% similar to the same reference sequence; however, they may only be 94% similar to each other. The strength of the reference based approach is that the methods are generally fast, scaling linearly with the number of sequences being clustered. A subtle alternative to this approach is to use a classifier to assign a taxonomy to each sequence so that sequences can be clustered at a desired level in the Linnean taxonomic hierarchy. Ultimately, this approach is an example of supervised classification.

The second approach has been referred to as *de novo* clustering. In this method, the similarity between sequences is used to cluster sequence rather than the similarity to a reference database. In contrast to the efficiency of closed-reference clustering, the speed of hierarchical *de novo* clustering algorithms scale quadratically with the number of unique sequences. The expansion in sequencing throughput combined with sequencing errors inflates the number of unique sequences resulting in the need for large amounts of memory and time to cluster the sequences. If error rates can be reduced through stringent quality control measures then these problems can be overcome (REF). As an alternative, heuristics have been developed to approximate the clustering of hierarchical methods. Previous comparisons of hierarchical and heuristic algorithms have shown that the average neighbor algorithm, a hierarchical algorithm outperforms the other *de novo* clustering algorithm. An early analysis using 16S rRNA gene sequence data generated using the 454 sequencing platform found that if these methods were applied to the same dataset using a subset of the sequences then a different number of OTUs were observed compared to clustering the full dataset and rarefying to the same number of sequences. Because the initial subsampling of the dataset was not repeated in the earlier analysis, it is unclear whether the result was product of the algorithm or sampling. One explanation could be that the clusters are getting better with additional sampling. Another observed problem with *de novo* clustering is that because it is necessary to break ties when assigning sequences to OTUs, clustering the same data multiple times may result in different clustering assignments. Whether the differences in assignments is meaningful is unclear; however the variation in results could represent equally valid clustering of the data. The strength of *de novo* clustering is its independence of references for carrying out the clustering step. After clustering, the classification of each sequence can be used to obtain a consensus classification for the OTU (ref). For this reason, *de novo* clustering has been preferred across the field. In contrast to closed-reference clustering, *de novo* clustering is an example of unsupervised clustering.

The third approach is a hybrid of the closed-reference and *de novo* approaches. This approach has been called open-reference clustering. This method involves performing closed-reference clustering followed by *de novo* clustering on those sequences that are not sufficiently similar to the reference. This method should exploit the strengths of both closed-referene and *de novo* clustering; however, the different OTU definitions generated by both approaches poses a possible problem when the methods are combined. An alternative to this approach has been to classify sequences to a bacterial family or genus and then assigned to OTUs within those levels (REF). For example, all sequences assigned to the *Porphyromonadaceae* would then be assigned to OTUs using the average neighbor algorithm. Those sequences that did not classify to a known family would also be clustered using the average neighbor algorithm. An advantage of this approach is that it lends itself nicely to parallelization since each taxonomic group (e.g. each family) is seen as being independent and can be processed separately. Such an approach would overcome the difficulty of mixing OTU definitions between the closed-reference and *de novo* approaches.

The growth in options for assigning sequences using each of these three broad approaches has been considerable. It has been difficult to objectively assess the quality of OTU assignments. Some have focused on the time and memory required to process a dataset (REFS). These are valid parameters to assess when judging a clustering algorithm, but have little to say about the quality of the clustering. Others have attempted to judge the quality of an algorithm by its ability to generate data that parallels classification data. This approach is problematic because bacterial taxonomy often reflects the biases amongst bacterial systematicists and the rates of evolution across lineages are not the same. We recently proposed an approach for evaluating OTU assignments using the similarity between sequences (REF). Those sequences that were similar to each other and found in the same OTU were called true positives while those that were similar and found in different OTUs were called false negatives. Meanwhile, those sequences that were different from each other and found in the same OTU were called false positives and those that were dissimilar and found in different OTUs were called true negatives. Counting the frequency of these different classes allowed us to judge how each method balanced the ratio of true positives and negatives to false positives and ratios using the Matthew's correlation coefficient (MCC; REF). That analysis focused on assessing *de novo* clustering algorithms and found that the average neighbor algorithm outperformed the other hierarchical and heuristic algorithms.

A recent analysis by He and colleagues (REF) attempted to characterize the three general clustering approaches by focusing on what they called stability. They defined stability as the ability of an algorithm to provide the same clustering on a subset of the data as was found in the full dataset. Related to this, the authors expressed concern that because some algorithms use a random number generator to break ties there may be further instability between executions of algorithm. Their concept of stability does not account for the accuracy of the clustering and instead focuses on the precision of the clustering. A method may be very precise, but low in accuracy. In the current analysis, we attempted to assess the accuracy and precision of the various clustering algorithms. Building on our previous analysis of clustering algorithms, our hypothesis was that the algorithms praised by the He study for their stability actually suffered a lack of accuracy. In addition, we assess these parameters in light of sequence quality using the original 454 dataset and a larger and more modern dataset generated using the MiSeq platform.


## Results

***Summary of He study.*** We sought to identify the more critical analyses performed in the He study. Similar to their study, we obtained the Canadian soil dataset from Roesch et al. (REF) and processed the sequences as described in their analysis. In our opinion there were three important tests. First, was to quantify whether the clustering observed for a subset of the data represented the same clustering that was found with the full dataset. The He study found that when they used the open and closed-reference methods clusters formed using the subset data most closely resembled those of the full dataset. Among the *de novo* clustering methods they observed that the abundance-based greedy clustering (AGC) algorithm followed by single linkage (SL), distance-based greedy clustering (DGC), complete linkage (CL), and average linkage (AL) algorithms. They observed a broad range of MCC values among their AL replicates, which was not explained by the authors. Second, rarefaction curves calculated using clusters obtained using a portion of the dataset did not overlap with rarefaction curves generated using clusters generated from the full dataset. This result was originally observed in the Roesch study using the complete linkage algorithm and was reproduced in the He study where this result was more pronounced problem when using the CL, SL, and DGC algorithms relative to the other algorithms. Third, the authors attempted to describe the effects of the clustering instability on comparisons of communities. Such an analysis does not make sense for the *de novo* or open-reference approaches since the labels of the OTUs are not consistent between executions of the clustering algorithms. To overcome this, the authors selected representative sequences from OTUs and merged OTUs across different sized libraries to link OTUs. Regardless, the justification for this analysis is specious as the OTU assignments are based on the data available in the dataset when the sequences are clustered and comparing assignments in this manner are irreconcilable. We will attempt to replicate the first two observations.

***Clustering approaches vary in their stability.*** We first sought to assess calculated the MCC for for each of the clustering algorithms using 20, 40, 60, and 80% relative to the clusters formed by the algorithms using the full dataset (Figure 1A). Because a random number generator is used in some of algorithms to break ties where pairs of sequences have the same distance between them, similar to the He study, we replicated each algorithm and subsample 30 times. Across these sequencing depths, we observed that the stability of the SL and CL algorithms were highly sensitive to sampling effort relative to the AL, AGC, and DGC algorithms (Figure 1A). Our results (Figure 1B) largely confirmed those of Figure 4C of He study with one notable exception. In the He study, when comparing the OTUs formed using the AL algorithm with 60% of the data, they observed a mean MCC value of approximately 0.63 (95% confidence interval between approximately 0.15 and 0.75). In contrast, we observed a mean value of `r round(z[z$method=="an" & z$fraction==0.6, "mean"], 2)` (95% confidence interval between `r round(z[z$method=="an" & z$fraction==0.6, "lci"], 2)` and `r round(z[z$method=="an" & z$fraction==0.6, "uci"], 2)`). This result suggests that the AL algorithm was far more stabile than indicated in the He study.


***Effect of sampling depth on observed number of OTUs.*** Next, we sought to determine whether the number of OTUs observed when clustering a subset of the data was the same as that observed when rarefying the full dataset back to the number of sequences in the subset. The analyses from the He and Roesch studies both compared the number of observed OTUs from the subset to the average number of expected OTUs from the full dataset instead of to the 95% confidence interval of what would be expected from the full dataset.


***Methods vary in their accuracy.***


***Stability, accuracy, and precision affected by data quality.***


***Deep sampling of 16S rRNA genes.***
- V4 region not well represented in closed reference database


***Closed-reference clustering also has a precision problem.***





## Methods

***Roesch dataset processed according to He study***
After obtaining the 16S rRNA gene fragments from GenBank (accessions EF308591-EF361836), we followed the methods outlined by the He study by removing any sequence that contained an ambiguous base, was identified as being a chimera, and fell outside a defined sequence length. Although they reported observing a total of 50,542 sequences that were represented by 13,293 unique sequences, we obtained a total of `r length(scan("data/he/canada_soil.good.unique.pick.redundant.fasta", what="", sep="\n", quiet=T))/2` sequences that were represented by `r length(scan("data/he/canada_soil.good.unique.pick.fasta", what="", sep="\n", quiet=T))/2` unique sequences. Similar to the He study, we randomly sampled, without replacement, 20, 40, 60, and 80% of the sequences from the full data set. The random sampling was repeated 30 times. The order of the sequences in the full dataset was randomly permuted without replacement to generate an additional 30 datasets. For the hierarchical clustering algorithms and to generate a distance matrix, the pairwise distances between sequences were calculated in mothur using the pairwise.seqs command with the default Needleman-Wunsch alignment algorithm and parameters. Execution of the clustering algorithms was performed as described in the original He study using mothur and QIIME as appropriate.
